{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666d4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "import datetime\n",
    "import os\n",
    "from tueplots import bundles\n",
    "from tueplots.constants.color import rgb\n",
    "import sklearn as sk\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import dload\n",
    "import geopandas\n",
    "from shapely.geometry import Point, Polygon\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17b91d59",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebe8ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accident data import completed\n"
     ]
    }
   ],
   "source": [
    "### Jonathans Code \n",
    "# Adjust nrows only for testing purposes (faster testing of new code)\n",
    "nrows = None\n",
    "try:\n",
    "    accidents = pd.read_csv('FARS2021NationalCSV/accident.csv',encoding='WINDOWS-1252',nrows=nrows)\n",
    "    drimpair = pd.read_csv('FARS2021NationalCSV/drimpair.csv',encoding='WINDOWS-1252',nrows=nrows)\n",
    "    driverrf = pd.read_csv('FARS2021NationalCSV/driverrf.csv',encoding='WINDOWS-1252',nrows=nrows)\n",
    "    vehicle = pd.read_csv('FARS2021NationalCSV/vehicle.csv',encoding='WINDOWS-1252',nrows=nrows, usecols=['ST_CASE','DR_DRINK','L_TYPE','L_STATUS','CDL_STAT','SPEEDREL'])\n",
    "    person = pd.read_csv('FARS2021NationalCSV/person.csv',encoding='WINDOWS-1252',nrows=nrows, usecols=['ST_CASE','PER_TYP','AGE','SEXNAME','DRINKINGNAME','ALC_DETNAME','ALC_STATUSNAME','ATST_TYPNAME','ALC_RES','ALC_RESNAME','DRUGS','DRUGSNAME','DRUG_DET','DRUG_DETNAME'])\n",
    "    crashrf = pd.read_csv('FARS2021NationalCSV/crashrf.csv',encoding='WINDOWS-1252',nrows=nrows)\n",
    "    accidents = pd.merge(accidents,drimpair.loc[:,'ST_CASE':],on=['ST_CASE'])\n",
    "    accidents = pd.merge(accidents,driverrf.loc[:,'ST_CASE':],on=['ST_CASE','VEH_NO'])\n",
    "    accidents = pd.merge(accidents,vehicle.loc[:,'ST_CASE':],on=['ST_CASE'],suffixes=('', '_y'))\n",
    "    accidents.drop(accidents.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "    accidents = pd.merge(accidents,person.loc[:,'ST_CASE':],on=['ST_CASE'],suffixes=('', '_y'))\n",
    "    accidents.drop(accidents.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "    accidents = pd.merge(accidents,crashrf.loc[:,'ST_CASE':],on=['ST_CASE'],suffixes=('', '_y'))\n",
    "    accidents.drop(accidents.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "    del drimpair, driverrf, vehicle, person, crashrf\n",
    "except:\n",
    "    print('ERROR')\n",
    "    with open('FARS2021NationalCSV/accident.csv', 'rb') as f:\n",
    "        result = chardet.detect(f.read())  # or readline if the file is large\n",
    "    accidents = pd.read_csv('FARS2021NationalCSV/accident.csv',encoding=result)\n",
    "    print(result)\n",
    "accidents['date'] = pd.to_datetime(accidents[['YEAR','MONTH','DAY']])\n",
    "print('accident data import completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3461cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a025ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in accidents.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d384f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['PER_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents = pd.read_csv('FARS2021NationalCSV/accident.csv',encoding='WINDOWS-1252',low_memory=False)\n",
    "drugs = pd.read_csv('FARS2021NationalCSV/drugs.csv',encoding='WINDOWS-1252',low_memory=False) \n",
    "person = pd.read_csv('FARS2021NationalCSV/person.csv',encoding='WINDOWS-1252',low_memory=False)\n",
    "\n",
    "\n",
    "### Here we should do the data preprocessibg (especially merging the dataset removing bad values etc)\n",
    "\n",
    "\n",
    "\n",
    "''' Other data '''\n",
    "\n",
    "## This is the amount of lane miles by every state, ordered alphaetically (like in the lists we are using. \n",
    "## Data is taken from https://blog.cubitplanning.com/2010/02/road-miles-by-state/\n",
    "## There is a reliable data source linked. @TODO Use data from actual reputable source-\n",
    "\n",
    "\n",
    "states = [210531,36009,146465,210729,396540,185486,45916,14069,3445,275376,272662,9799,107568,306658,202707,235549,286606,166971,134115,46736,71129,77730,256579,290618,162088,\t277504,150446,193996,100805,33391,85108,150216,240489,229011,178845,262492,238754,162101,251708,12664,166594,166635,203850,683533,102031,29273,164132,167632,80167,239318,62620]\n",
    "## US census, ordered by states\n",
    "state_pop = pd.read_csv('Daten/population.csv')\n",
    " ##Last 'state is Puerto Rico, hence we dont include it. First lines include meta data, that is irrelevant to us.\n",
    "state_pop = state_pop.iloc[14:]\n",
    "state_pop = state_pop.iloc[:-1]\n",
    "## We remove unwanted columns (all besides state name and amount), so the dataset becomes easier to work with. \n",
    "col = state_pop.columns.values\n",
    "col = np.delete(col,[4,7])\n",
    "state_pop = state_pop.drop(col,axis=1)\n",
    "\n",
    "#Prepare the state drawing of the US.\n",
    "US_state_shape = geopandas.read_file('Daten/States shape data/cb_2018_us_state_500k.shp')\n",
    "US_state_shape['STATENAME'] = US_state_shape['NAME']\n",
    "print(US_state_shape.head())\n",
    "\n",
    "save_US = US_state_shape.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa09162",
   "metadata": {},
   "source": [
    "Histogram drunk drivers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc50bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Note: We are lacking the preprocessing step here. Thus currently not runable.'''\n",
    "#\n",
    "### Prepare array the historgram \n",
    "histWhole = [0 for k in range(100)]\n",
    "histDrunk = [0 for k in range(100)]\n",
    "for i in range(100):\n",
    "    for j in range(len(ages)):\n",
    "        if ages[j] == i: \n",
    "            histWhole[i] = histWhole[i] + 1\n",
    "            if alc[j] != 0:\n",
    "                histDrunk[i] = histDrunk[i] + 1\n",
    "                \n",
    "### Plot the histograms\n",
    "plt.title('Histogram of Accidents by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Amounts')\n",
    "plt.bar([i for i in range(100)],histWhole,label='All')\n",
    "plt.bar([i for i in range(100)],histDrunk,label='Drunk')\n",
    "plt.legend()               \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8ce29",
   "metadata": {},
   "source": [
    "Age group drunk drivers\n",
    "\n",
    "(again not usable, preprocessing. Check Data_Analysis_Main_Copy if needed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make into age group\n",
    "bins = [i for i in range(17)]\n",
    "res = [0 for i in range(17)]\n",
    "for x in ages:\n",
    "    if x >= 85: res[-1] = res[-1] +1\n",
    "    else:\n",
    "        x = x - (x % 5)\n",
    "        b = int(x / 5)\n",
    "        res[b] = res[b] +1\n",
    "tot = len(ages)\n",
    "procent_age = [i*100 / tot for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ef819",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Collect age data of the US government\n",
    "us_cens = pd.read_csv('US_CENSUS/2021agesex_table1.csv',encoding='WINDOWS-1252',low_memory=False)\n",
    "ag = us_cens['Unnamed: 2'].tolist() ##The columns have bad names\n",
    "ag[6]\n",
    "## Make lists of age distribution\n",
    "x = [i for i in range(17)]\n",
    "y = [float(ag[i+6]) for i in range(17)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248132b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot\n",
    "### Todo: make nice\n",
    "plt.plot(x,y, label='Total Population')\n",
    "plt.plot(x,procent_age,label='Drivers of Fatal Accidents')\n",
    "plt.legend()\n",
    "plt.ylabel('Perecentage')\n",
    "plt.xlabel('Age Group, blocks of 5 years')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8252503",
   "metadata": {},
   "source": [
    "Plot all accidents on map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b384a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Better visibility\n",
    "accidents = accidents.loc[accidents['LONGITUD'] <= 200] ##Redundant after preprocessing\n",
    "accidents = accidents.loc[accidents['STATENAME'] != 'Hawaii']\n",
    "accidents = accidents.loc[accidents['STATENAME'] != 'Alaska']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot accidents on map '''\n",
    "crs = {'init':'epsg:4326'}\n",
    "geometry = [Point(xy) for xy in zip(accidents['LONGITUD'], accidents['LATITUDE'])]\n",
    "geo_data = gpd.GeoDataFrame(accidents,crs=crs,geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO improve plot\n",
    "geo_data.plot(geo_data['STATE'],figsize=(25,25))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ce09d",
   "metadata": {},
   "source": [
    "Accidents by lane miles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f85a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data is calculated\n",
    "pop_val = state_pop['POPESTIMATE2021'].values\n",
    "statenames = state_pop['NAME'].values\n",
    "counts = []\n",
    "## For every state count amount of accidents.\n",
    "# TODO remove non unique ids. (maybe, depending on what we want)\n",
    "for x in statenames:\n",
    "    counts.append(accidents['STATENAME'].value_counts()[x])    \n",
    "state_pop.insert(2,'Accidents/State',counts,True)\n",
    "state_pop.insert(3,'Lane Miles',states,True)\n",
    "## res is the value we wanted to calculate\n",
    "res = np.array(counts) / ( states * pop_val )\n",
    "b = np.sort(res) ## We want to rescale the map accordingly\n",
    "state_pop.insert(4,'AccidentsPerCapitaPerLaneMile',res,True)\n",
    "state_pop.rename(columns = {'NAME':'STATENAME'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e308350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot\n",
    "US_state_shape = save_US.copy()\n",
    "US_state_shape = geopandas.GeoDataFrame(pd.merge(US_state_shape,state_pop, on=['STATENAME']))\n",
    "\n",
    "US_state_shape.plot(column='AccidentsPerCapitaPerLaneMile',vmin=b[0],vmax=b[-3])\n",
    "plt.xlim(-180,-60)\n",
    "plt.ylim(20,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79fe86a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
