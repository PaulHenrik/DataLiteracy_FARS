{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666d4086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' TODO\\nspecify a human error metric (true false) etc.\\nplot probabilites of human error by state etc.\\nhuman error by age\\nage in comparsion to us population (done)\\ntime? maybe make three slots \\ndrinking and time \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "import datetime\n",
    "import os\n",
    "from tueplots import bundles\n",
    "from tueplots.constants.color import rgb\n",
    "import sklearn as sk\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import dload\n",
    "import geopandas\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "''' TODO\n",
    "specify a human error metric (true false) etc.\n",
    "plot probabilites of human error by state etc.\n",
    "human error by age\n",
    "age in comparsion to us population (done)\n",
    "time? maybe make three slots \n",
    "drinking and time \n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17b91d59",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebe8ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accident data import completed\n"
     ]
    }
   ],
   "source": [
    "### Jonathans Code \n",
    "# Adjust nrows only for testing purposes (faster testing of new code) Test\n",
    "nrows = None\n",
    "try:\n",
    "    accidents = pd.read_csv('FARS2021NationalCSV/accident.csv',encoding='WINDOWS-1252',nrows=nrows)\n",
    "    drimpair = pd.read_csv('FARS2021NationalCSV/drimpair.csv',encoding='WINDOWS-1252',nrows=nrows)\n",
    "    driverrf = pd.read_csv('FARS2021NationalCSV/driverrf.csv',encoding='WINDOWS-1252',nrows=nrows)\n",
    "    vehicle = pd.read_csv('FARS2021NationalCSV/vehicle.csv',encoding='WINDOWS-1252',nrows=nrows, usecols=['ST_CASE','DR_DRINK','L_TYPE','L_STATUS','CDL_STAT','SPEEDREL'])\n",
    "    person = pd.read_csv('FARS2021NationalCSV/person.csv',encoding='WINDOWS-1252',nrows=nrows, usecols=['ST_CASE','PER_TYP','AGE','SEXNAME','DRINKINGNAME','ALC_DETNAME','ALC_STATUSNAME','ATST_TYPNAME','ALC_RES','ALC_RESNAME','DRUGS','DRUGSNAME','DRUG_DET','DRUG_DETNAME'])\n",
    "    crashrf = pd.read_csv('FARS2021NationalCSV/crashrf.csv',encoding='WINDOWS-1252',nrows=nrows)\n",
    "    accidents = pd.merge(accidents,drimpair.loc[:,'ST_CASE':],on=['ST_CASE'])\n",
    "    accidents = pd.merge(accidents,driverrf.loc[:,'ST_CASE':],on=['ST_CASE','VEH_NO'])\n",
    "    accidents = pd.merge(accidents,vehicle.loc[:,'ST_CASE':],on=['ST_CASE'],suffixes=('', '_y'))\n",
    "    accidents.drop(accidents.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "    accidents = pd.merge(accidents,person.loc[:,'ST_CASE':],on=['ST_CASE'],suffixes=('', '_y'))\n",
    "    accidents.drop(accidents.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "    accidents = pd.merge(accidents,crashrf.loc[:,'ST_CASE':],on=['ST_CASE'],suffixes=('', '_y'))\n",
    "    accidents.drop(accidents.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "    del drimpair, driverrf, vehicle, person, crashrf\n",
    "except:\n",
    "    print('ERROR')\n",
    "    with open('FARS2021NationalCSV/accident.csv', 'rb') as f:\n",
    "        result = chardet.detect(f.read())  # or readline if the file is large\n",
    "    accidents = pd.read_csv('FARS2021NationalCSV/accident.csv',encoding=result)\n",
    "    print(result)\n",
    "accidents['date'] = pd.to_datetime(accidents[['YEAR','MONTH','DAY']])\n",
    "print('accident data import completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d384f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = accidents.loc[accidents['PER_TYP'] == 1] ## Subset of only the drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "653b53a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find header.dxf (GDAL_DATA is not defined)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  STATEFP   STATENS     AFFGEOID GEOID STUSPS            NAME LSAD  \\\n",
      "0      28  01779790  0400000US28    28     MS     Mississippi   00   \n",
      "1      37  01027616  0400000US37    37     NC  North Carolina   00   \n",
      "2      40  01102857  0400000US40    40     OK        Oklahoma   00   \n",
      "3      51  01779803  0400000US51    51     VA        Virginia   00   \n",
      "4      54  01779805  0400000US54    54     WV   West Virginia   00   \n",
      "\n",
      "          ALAND       AWATER  \\\n",
      "0  121533519481   3926919758   \n",
      "1  125923656064  13466071395   \n",
      "2  177662925723   3374587997   \n",
      "3  102257717110   8528531774   \n",
      "4   62266474513    489028543   \n",
      "\n",
      "                                            geometry       STATENAME  \n",
      "0  MULTIPOLYGON (((-88.50297 30.21523, -88.49176 ...     Mississippi  \n",
      "1  MULTIPOLYGON (((-75.72681 35.93584, -75.71827 ...  North Carolina  \n",
      "2  POLYGON ((-103.00257 36.52659, -103.00219 36.6...        Oklahoma  \n",
      "3  MULTIPOLYGON (((-75.74241 37.80835, -75.74151 ...        Virginia  \n",
      "4  POLYGON ((-82.64320 38.16909, -82.64300 38.169...   West Virginia  \n"
     ]
    }
   ],
   "source": [
    "### Here we should do the data preprocessibg (especially merging the dataset removing bad values etc)\n",
    "\n",
    "\n",
    "\n",
    "''' Other data '''\n",
    "\n",
    "## This is the amount of lane miles by every state, ordered alphaetically (like in the lists we are using. \n",
    "## Data is taken from https://blog.cubitplanning.com/2010/02/road-miles-by-state/\n",
    "## There is a reliable data source linked. @TODO Use data from actual reputable source-\n",
    "\n",
    "\n",
    "states = [210531,36009,146465,210729,396540,185486,45916,14069,3445,275376,272662,9799,107568,306658,202707,235549,286606,166971,134115,46736,71129,77730,256579,290618,162088,\t277504,150446,193996,100805,33391,85108,150216,240489,229011,178845,262492,238754,162101,251708,12664,166594,166635,203850,683533,102031,29273,164132,167632,80167,239318,62620]\n",
    "## US census, ordered by states\n",
    "state_pop = pd.read_csv('Daten/population.csv')\n",
    " ##Last 'state is Puerto Rico, hence we dont include it. First lines include meta data, that is irrelevant to us.\n",
    "state_pop = state_pop.iloc[14:]\n",
    "state_pop = state_pop.iloc[:-1]\n",
    "## We remove unwanted columns (all besides state name and amount), so the dataset becomes easier to work with. \n",
    "col = state_pop.columns.values\n",
    "col = np.delete(col,[4,7])\n",
    "state_pop = state_pop.drop(col,axis=1)\n",
    "\n",
    "#Prepare the state drawing of the US.\n",
    "US_state_shape = geopandas.read_file('Daten/States shape data/cb_2018_us_state_500k.shp')\n",
    "US_state_shape['STATENAME'] = US_state_shape['NAME']\n",
    "print(US_state_shape.head())\n",
    "\n",
    "save_US = US_state_shape.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f17e2",
   "metadata": {},
   "source": [
    "**Define human error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2571bd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01371694153741046\n",
      "20370\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'drivers_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m drivers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(drivers\u001b[38;5;241m.\u001b[39mloc[drivers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPEEDREL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m4\u001b[39m]))\n\u001b[1;32m---> 11\u001b[0m drivers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_COL\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdrivers_\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPEEDREL\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'drivers_' is not defined"
     ]
    }
   ],
   "source": [
    "## Note: we will only consider the drivers here\n",
    "\n",
    "## Playing around a little\n",
    "x = len(drivers.loc[drivers['DR_DRINK']==1])\n",
    "y = len(drivers.loc[drivers['DR_DRINK']==0])\n",
    "print(x/y)\n",
    "\n",
    "drivers['L_TYPE']\n",
    "print(len(drivers.loc[drivers['SPEEDREL']==4]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c65e878e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulh\\AppData\\Local\\Temp\\ipykernel_10104\\350307789.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drivers['HUMAN_CAUSE'] = 1 - (1 - drivers['DR_DRINK'])*(drivers['L_TYPE'])*(1-drivers['SPEEDREL'].map(speeding_stats) )\n"
     ]
    }
   ],
   "source": [
    "def speeding_stats(val):\n",
    "    if val >= 1: return 1\n",
    "    return 0\n",
    "\n",
    "drivers['HUMAN_CAUSE'] = 1 - (1 - drivers['DR_DRINK'])*(drivers['L_TYPE'])*(1-drivers['SPEEDREL'].map(speeding_stats) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "568f7faf",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.11 GiB for an array with shape (59, 2528354) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdrivers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdrivers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHUMAN_CAUSE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1292\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1294\u001b[0m \n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1093\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1091\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(labels, key)\n\u001b[0;32m   1092\u001b[0m inds \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3896\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3900\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3901\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3902\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3903\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3884\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take\u001b[39m(\n\u001b[0;32m   3874\u001b[0m     \u001b[38;5;28mself\u001b[39m: NDFrameT,\n\u001b[0;32m   3875\u001b[0m     indices,\n\u001b[0;32m   3876\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   3877\u001b[0m     convert_indices: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3878\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3879\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3880\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` allowing specification of additional args.\u001b[39;00m\n\u001b[0;32m   3881\u001b[0m \n\u001b[0;32m   3882\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3883\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3884\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3886\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[0;32m   3887\u001b[0m         indices,\n\u001b[0;32m   3888\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[0;32m   3889\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3890\u001b[0m         convert_indices\u001b[38;5;241m=\u001b[39mconvert_indices,\n\u001b[0;32m   3891\u001b[0m     )\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5980\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[0;32m   5978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mconsolidate()\n\u001b[1;32m-> 5980\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_protect_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5968\u001b[0m, in \u001b[0;36mNDFrame._protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f()\n\u001b[0;32m   5967\u001b[0m blocks_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[1;32m-> 5968\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mblocks) \u001b[38;5;241m!=\u001b[39m blocks_before:\n\u001b[0;32m   5970\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5978\u001b[0m, in \u001b[0;36mNDFrame._consolidate_inplace.<locals>.f\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m():\n\u001b[1;32m-> 5978\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:686\u001b[0m, in \u001b[0;36mBaseBlockManager.consolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    684\u001b[0m bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    685\u001b[0m bm\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 686\u001b[0m \u001b[43mbm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_consolidate_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bm\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1871\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1871\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m \u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1872\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1873\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs \u001b[38;5;241m=\u001b[39m _consolidate_with_refs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2329\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2327\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2328\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2329\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_merge_blocks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2330\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroup_blocks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcan_consolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_can_consolidate\u001b[49m\n\u001b[0;32m   2331\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2332\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2381\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2374\u001b[0m new_values: ArrayLike\n\u001b[0;32m   2376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   2377\u001b[0m     \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001b[39;00m\n\u001b[0;32m   2378\u001b[0m     \u001b[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001b[39;00m\n\u001b[0;32m   2379\u001b[0m     \u001b[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[39;00m\n\u001b[0;32m   2380\u001b[0m     \u001b[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001b[39;00m\n\u001b[1;32m-> 2381\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   2382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2383\u001b[0m     bvals \u001b[38;5;241m=\u001b[39m [blk\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m blocks]\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    281\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.11 GiB for an array with shape (59, 2528354) and data type int64"
     ]
    }
   ],
   "source": [
    "len(drivers.loc[drivers['HUMAN_CAUSE']==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa09162",
   "metadata": {},
   "source": [
    "Histogram drunk drivers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc50bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Note: We are lacking the preprocessing step here. Thus currently not runable.'''\n",
    "#\n",
    "### Prepare array the historgram \n",
    "histWhole = [0 for k in range(100)]\n",
    "histDrunk = [0 for k in range(100)]\n",
    "for i in range(100):\n",
    "    for j in range(len(ages)):\n",
    "        if ages[j] == i: \n",
    "            histWhole[i] = histWhole[i] + 1\n",
    "            if alc[j] != 0:\n",
    "                histDrunk[i] = histDrunk[i] + 1\n",
    "                \n",
    "### Plot the histograms\n",
    "plt.title('Histogram of Accidents by Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Amounts')\n",
    "plt.bar([i for i in range(100)],histWhole,label='All')\n",
    "plt.bar([i for i in range(100)],histDrunk,label='Drunk')\n",
    "plt.legend()               \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8ce29",
   "metadata": {},
   "source": [
    "Age group drunk drivers\n",
    "\n",
    "(again not usable, preprocessing. Check Data_Analysis_Main_Copy if needed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make into age group\n",
    "bins = [i for i in range(17)]\n",
    "res = [0 for i in range(17)]\n",
    "for x in ages:\n",
    "    if x >= 85: res[-1] = res[-1] +1\n",
    "    else:\n",
    "        x = x - (x % 5)\n",
    "        b = int(x / 5)\n",
    "        res[b] = res[b] +1\n",
    "tot = len(ages)\n",
    "procent_age = [i*100 / tot for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ef819",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Collect age data of the US government\n",
    "us_cens = pd.read_csv('US_CENSUS/2021agesex_table1.csv',encoding='WINDOWS-1252',low_memory=False)\n",
    "ag = us_cens['Unnamed: 2'].tolist() ##The columns have bad names\n",
    "ag[6]\n",
    "## Make lists of age distribution\n",
    "x = [i for i in range(17)]\n",
    "y = [float(ag[i+6]) for i in range(17)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248132b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot\n",
    "### Todo: make nice\n",
    "plt.plot(x,y, label='Total Population')\n",
    "plt.plot(x,procent_age,label='Drivers of Fatal Accidents')\n",
    "plt.legend()\n",
    "plt.ylabel('Perecentage')\n",
    "plt.xlabel('Age Group, blocks of 5 years')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8252503",
   "metadata": {},
   "source": [
    "Plot all accidents on map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b384a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Better visibility\n",
    "accidents = accidents.loc[accidents['LONGITUD'] <= 200] ##Redundant after preprocessing\n",
    "accidents = accidents.loc[accidents['STATENAME'] != 'Hawaii']\n",
    "accidents = accidents.loc[accidents['STATENAME'] != 'Alaska']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot accidents on map '''\n",
    "crs = {'init':'epsg:4326'}\n",
    "geometry = [Point(xy) for xy in zip(accidents['LONGITUD'], accidents['LATITUDE'])]\n",
    "geo_data = gpd.GeoDataFrame(accidents,crs=crs,geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d96388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO improve plot\n",
    "geo_data.plot(geo_data['STATE'],figsize=(25,25))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5ce09d",
   "metadata": {},
   "source": [
    "Accidents by lane miles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f85a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data is calculated\n",
    "pop_val = state_pop['POPESTIMATE2021'].values\n",
    "statenames = state_pop['NAME'].values\n",
    "counts = []\n",
    "## For every state count amount of accidents.\n",
    "# TODO remove non unique ids. (maybe, depending on what we want)\n",
    "for x in statenames:\n",
    "    counts.append(accidents['STATENAME'].value_counts()[x])    \n",
    "state_pop.insert(2,'Accidents/State',counts,True)\n",
    "state_pop.insert(3,'Lane Miles',states,True)\n",
    "## res is the value we wanted to calculate\n",
    "res = np.array(counts) / ( states * pop_val )\n",
    "b = np.sort(res) ## We want to rescale the map accordingly\n",
    "state_pop.insert(4,'AccidentsPerCapitaPerLaneMile',res,True)\n",
    "state_pop.rename(columns = {'NAME':'STATENAME'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e308350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot\n",
    "US_state_shape = save_US.copy()\n",
    "US_state_shape = geopandas.GeoDataFrame(pd.merge(US_state_shape,state_pop, on=['STATENAME']))\n",
    "\n",
    "US_state_shape.plot(column='AccidentsPerCapitaPerLaneMile',vmin=b[0],vmax=b[-3])\n",
    "plt.xlim(-180,-60)\n",
    "plt.ylim(20,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79fe86a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
